{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.backbone import StackedHGNetV1\n",
    "from lib.utility import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config_300W:\n",
    "    def __init__(self):\n",
    "        self.classes_num = [68, 9, 68]\n",
    "        self.edge_info = (\n",
    "                (False, (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)),  # FaceContour\n",
    "                (False, (17, 18, 19, 20, 21)),  # RightEyebrow\n",
    "                (False, (22, 23, 24, 25, 26)),  # LeftEyebrow\n",
    "                (False, (27, 28, 29, 30)),  # NoseLine\n",
    "                (False, (31, 32, 33, 34, 35)),  # Nose\n",
    "                (True, (36, 37, 38, 39, 40, 41)),  # RightEye\n",
    "                (True, (42, 43, 44, 45, 46, 47)),  # LeftEye\n",
    "                (True, (48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59)),  # OuterLip\n",
    "                (True, (60, 61, 62, 63, 64, 65, 66, 67)),  # InnerLip\n",
    "            )\n",
    "        self.nstack = 4\n",
    "        self.add_coord = True\n",
    "        self.decoder_type = \"default\"\n",
    "        self.width = 256\n",
    "        self.height = 256\n",
    "        self.use_AAM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config_WFLW:\n",
    "    def __init__(self):\n",
    "        self.classes_num = [98, 9, 98]\n",
    "        self.edge_info = (\n",
    "                (False, (\n",
    "                    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
    "                    27,\n",
    "                    28, 29, 30, 31, 32)),  # FaceContour\n",
    "                (True, (33, 34, 35, 36, 37, 38, 39, 40, 41)),  # RightEyebrow\n",
    "                (True, (42, 43, 44, 45, 46, 47, 48, 49, 50)),  # LeftEyebrow\n",
    "                (False, (51, 52, 53, 54)),  # NoseLine\n",
    "                (False, (55, 56, 57, 58, 59)),  # Nose\n",
    "                (True, (60, 61, 62, 63, 64, 65, 66, 67)),  # RightEye\n",
    "                (True, (68, 69, 70, 71, 72, 73, 74, 75)),  # LeftEye\n",
    "                (True, (76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87)),  # OuterLip\n",
    "                (True, (88, 89, 90, 91, 92, 93, 94, 95)),  # InnerLip\n",
    "            )\n",
    "        self.nstack = 4\n",
    "        self.add_coord = True\n",
    "        self.decoder_type = \"default\"\n",
    "        self.width = 256\n",
    "        self.height = 256\n",
    "        self.use_AAM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19573/649091508.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path,map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_300W = Config_300W()\n",
    "net_300W = StackedHGNetV1(config=config_300W,\n",
    "                        classes_num=config_300W.classes_num,\n",
    "                        edge_info=config_300W.edge_info,\n",
    "                        nstack=config_300W.nstack,\n",
    "                        add_coord=config_300W.add_coord,\n",
    "                        decoder_type=config_300W.decoder_type)\n",
    "# Pretrained Model\n",
    "model_path = \"300W_STARLoss_NME_2_87.pkl\"\n",
    "checkpoint = torch.load(model_path,map_location=torch.device('cpu'))\n",
    "net_300W.load_state_dict(checkpoint[\"net\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_WFLW = Config_WFLW()\n",
    "net_WFLW = StackedHGNetV1(config=config_WFLW,\n",
    "                        classes_num=config_WFLW.classes_num,\n",
    "                        edge_info=config_WFLW.edge_info,\n",
    "                        nstack=config_WFLW.nstack,\n",
    "                        add_coord=config_WFLW.add_coord,\n",
    "                        decoder_type=config_WFLW.decoder_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedHGNetV1(\n",
       "  (pre): Sequential(\n",
       "    (0): CoordConvTh(\n",
       "      (addcoords): AddCoordsTh()\n",
       "      (conv): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBlock(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (skip_layer): ConvBlock(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ResBlock(\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBlock(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (skip_layer): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBlock(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (skip_layer): ConvBlock(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hgs): ModuleList(\n",
       "    (0): Hourglass(\n",
       "      (coordconv): CoordConvTh(\n",
       "        (addcoords): AddCoordsTh()\n",
       "        (conv): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (up1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (low1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (low2): Hourglass(\n",
       "        (up1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (low1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (low2): Hourglass(\n",
       "          (up1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (low1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (low2): Hourglass(\n",
       "            (up1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (low1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low2): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low3): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          )\n",
       "          (low3): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        )\n",
       "        (low3): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      )\n",
       "      (low3): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    )\n",
       "    (1-3): 3 x Hourglass(\n",
       "      (coordconv): CoordConvTh(\n",
       "        (addcoords): AddCoordsTh()\n",
       "        (conv): Conv2d(261, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (up1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (low1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (low2): Hourglass(\n",
       "        (up1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (low1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (low2): Hourglass(\n",
       "          (up1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (low1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (low2): Hourglass(\n",
       "            (up1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (low1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low2): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low3): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          )\n",
       "          (low3): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        )\n",
       "        (low3): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      )\n",
       "      (low3): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    )\n",
       "  )\n",
       "  (features): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_heatmaps): ModuleList(\n",
       "    (0-3): 4 x ConvBlock(\n",
       "      (conv): Conv2d(256, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (e2h_transform): E2HTransform()\n",
       "  (out_edgemaps): ModuleList(\n",
       "    (0-3): 4 x ConvBlock(\n",
       "      (conv): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out_pointmaps): ModuleList(\n",
       "    (0-3): 4 x ConvBlock(\n",
       "      (conv): Conv2d(256, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (merge_edgemaps): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(9, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (merge_pointmaps): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(68, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (edgemap_act): Activation(kind=sigmoid, channel=9)\n",
       "  (pointmap_act): Activation(kind=sigmoid, channel=68)\n",
       "  (merge_features): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (merge_heatmaps): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(68, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (heatmap_act): Activation(kind=in+relu, channel=68)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_300W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackedHGNetV1(\n",
       "  (pre): Sequential(\n",
       "    (0): CoordConvTh(\n",
       "      (addcoords): AddCoordsTh()\n",
       "      (conv): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBlock(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (skip_layer): ConvBlock(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ResBlock(\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBlock(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (skip_layer): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): ConvBlock(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (skip_layer): ConvBlock(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hgs): ModuleList(\n",
       "    (0): Hourglass(\n",
       "      (coordconv): CoordConvTh(\n",
       "        (addcoords): AddCoordsTh()\n",
       "        (conv): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (up1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (low1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (low2): Hourglass(\n",
       "        (up1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (low1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (low2): Hourglass(\n",
       "          (up1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (low1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (low2): Hourglass(\n",
       "            (up1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (low1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low2): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low3): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          )\n",
       "          (low3): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        )\n",
       "        (low3): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      )\n",
       "      (low3): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    )\n",
       "    (1-3): 3 x Hourglass(\n",
       "      (coordconv): CoordConvTh(\n",
       "        (addcoords): AddCoordsTh()\n",
       "        (conv): Conv2d(261, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (up1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (low1): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (low2): Hourglass(\n",
       "        (up1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (low1): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (low2): Hourglass(\n",
       "          (up1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (low1): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (low2): Hourglass(\n",
       "            (up1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (low1): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low2): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (low3): ResBlock(\n",
       "              (relu): ReLU()\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv1): ConvBlock(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv2): ConvBlock(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (conv3): ConvBlock(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (skip_layer): ConvBlock(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "          )\n",
       "          (low3): ResBlock(\n",
       "            (relu): ReLU()\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv1): ConvBlock(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): ConvBlock(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): ConvBlock(\n",
       "              (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (skip_layer): ConvBlock(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        )\n",
       "        (low3): ResBlock(\n",
       "          (relu): ReLU()\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (skip_layer): ConvBlock(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      )\n",
       "      (low3): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    )\n",
       "  )\n",
       "  (features): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): ResBlock(\n",
       "        (relu): ReLU()\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (skip_layer): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_heatmaps): ModuleList(\n",
       "    (0-3): 4 x ConvBlock(\n",
       "      (conv): Conv2d(256, 98, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (e2h_transform): E2HTransform()\n",
       "  (out_edgemaps): ModuleList(\n",
       "    (0-3): 4 x ConvBlock(\n",
       "      (conv): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out_pointmaps): ModuleList(\n",
       "    (0-3): 4 x ConvBlock(\n",
       "      (conv): Conv2d(256, 98, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (merge_edgemaps): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(9, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (merge_pointmaps): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(98, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (edgemap_act): Activation(kind=sigmoid, channel=9)\n",
       "  (pointmap_act): Activation(kind=sigmoid, channel=98)\n",
       "  (merge_features): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (merge_heatmaps): ModuleList(\n",
       "    (0-2): 3 x ConvBlock(\n",
       "      (conv): Conv2d(98, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (heatmap_act): Activation(kind=in+relu, channel=98)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_WFLW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre.0.conv.weight torch.Size([64, 6, 7, 7])\n",
      "pre.0.conv.bias torch.Size([64])\n",
      "pre.0.bn.weight torch.Size([64])\n",
      "pre.0.bn.bias torch.Size([64])\n",
      "pre.1.bn1.weight torch.Size([64])\n",
      "pre.1.bn1.bias torch.Size([64])\n",
      "pre.1.conv1.conv.weight torch.Size([64, 64, 1, 1])\n",
      "pre.1.conv1.conv.bias torch.Size([64])\n",
      "pre.1.bn2.weight torch.Size([64])\n",
      "pre.1.bn2.bias torch.Size([64])\n",
      "pre.1.conv2.conv.weight torch.Size([64, 64, 3, 3])\n",
      "pre.1.conv2.conv.bias torch.Size([64])\n",
      "pre.1.bn3.weight torch.Size([64])\n",
      "pre.1.bn3.bias torch.Size([64])\n",
      "pre.1.conv3.conv.weight torch.Size([128, 64, 1, 1])\n",
      "pre.1.conv3.conv.bias torch.Size([128])\n",
      "pre.1.skip_layer.conv.weight torch.Size([128, 64, 1, 1])\n",
      "pre.1.skip_layer.conv.bias torch.Size([128])\n",
      "pre.3.bn1.weight torch.Size([128])\n",
      "pre.3.bn1.bias torch.Size([128])\n",
      "pre.3.conv1.conv.weight torch.Size([64, 128, 1, 1])\n",
      "pre.3.conv1.conv.bias torch.Size([64])\n",
      "pre.3.bn2.weight torch.Size([64])\n",
      "pre.3.bn2.bias torch.Size([64])\n",
      "pre.3.conv2.conv.weight torch.Size([64, 64, 3, 3])\n",
      "pre.3.conv2.conv.bias torch.Size([64])\n",
      "pre.3.bn3.weight torch.Size([64])\n",
      "pre.3.bn3.bias torch.Size([64])\n",
      "pre.3.conv3.conv.weight torch.Size([128, 64, 1, 1])\n",
      "pre.3.conv3.conv.bias torch.Size([128])\n",
      "pre.3.skip_layer.conv.weight torch.Size([128, 128, 1, 1])\n",
      "pre.3.skip_layer.conv.bias torch.Size([128])\n",
      "pre.4.bn1.weight torch.Size([128])\n",
      "pre.4.bn1.bias torch.Size([128])\n",
      "pre.4.conv1.conv.weight torch.Size([128, 128, 1, 1])\n",
      "pre.4.conv1.conv.bias torch.Size([128])\n",
      "pre.4.bn2.weight torch.Size([128])\n",
      "pre.4.bn2.bias torch.Size([128])\n",
      "pre.4.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "pre.4.conv2.conv.bias torch.Size([128])\n",
      "pre.4.bn3.weight torch.Size([128])\n",
      "pre.4.bn3.bias torch.Size([128])\n",
      "pre.4.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "pre.4.conv3.conv.bias torch.Size([256])\n",
      "pre.4.skip_layer.conv.weight torch.Size([256, 128, 1, 1])\n",
      "pre.4.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.coordconv.conv.weight torch.Size([256, 259, 1, 1])\n",
      "hgs.0.coordconv.conv.bias torch.Size([256])\n",
      "hgs.0.up1.bn1.weight torch.Size([256])\n",
      "hgs.0.up1.bn1.bias torch.Size([256])\n",
      "hgs.0.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.up1.bn2.weight torch.Size([128])\n",
      "hgs.0.up1.bn2.bias torch.Size([128])\n",
      "hgs.0.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.up1.bn3.weight torch.Size([128])\n",
      "hgs.0.up1.bn3.bias torch.Size([128])\n",
      "hgs.0.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low1.bn1.weight torch.Size([256])\n",
      "hgs.0.low1.bn1.bias torch.Size([256])\n",
      "hgs.0.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low1.bn2.weight torch.Size([128])\n",
      "hgs.0.low1.bn2.bias torch.Size([128])\n",
      "hgs.0.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low1.bn3.weight torch.Size([128])\n",
      "hgs.0.low1.bn3.bias torch.Size([128])\n",
      "hgs.0.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low2.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low2.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low2.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.low2.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low2.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low2.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low2.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.low2.low2.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low2.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low2.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low2.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.low2.low2.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low2.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.low2.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.0.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.0.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.0.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.0.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.0.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.0.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.0.low3.bn1.weight torch.Size([256])\n",
      "hgs.0.low3.bn1.bias torch.Size([256])\n",
      "hgs.0.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.0.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.0.low3.bn2.weight torch.Size([128])\n",
      "hgs.0.low3.bn2.bias torch.Size([128])\n",
      "hgs.0.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.0.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.0.low3.bn3.weight torch.Size([128])\n",
      "hgs.0.low3.bn3.bias torch.Size([128])\n",
      "hgs.0.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.0.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.0.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.0.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.coordconv.conv.weight torch.Size([256, 261, 1, 1])\n",
      "hgs.1.coordconv.conv.bias torch.Size([256])\n",
      "hgs.1.up1.bn1.weight torch.Size([256])\n",
      "hgs.1.up1.bn1.bias torch.Size([256])\n",
      "hgs.1.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.up1.bn2.weight torch.Size([128])\n",
      "hgs.1.up1.bn2.bias torch.Size([128])\n",
      "hgs.1.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.up1.bn3.weight torch.Size([128])\n",
      "hgs.1.up1.bn3.bias torch.Size([128])\n",
      "hgs.1.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low1.bn1.weight torch.Size([256])\n",
      "hgs.1.low1.bn1.bias torch.Size([256])\n",
      "hgs.1.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low1.bn2.weight torch.Size([128])\n",
      "hgs.1.low1.bn2.bias torch.Size([128])\n",
      "hgs.1.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low1.bn3.weight torch.Size([128])\n",
      "hgs.1.low1.bn3.bias torch.Size([128])\n",
      "hgs.1.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low2.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low2.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low2.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.low2.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low2.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low2.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low2.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.low2.low2.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low2.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low2.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low2.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.low2.low2.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low2.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.low2.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.1.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.1.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.1.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.1.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.1.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.1.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.1.low3.bn1.weight torch.Size([256])\n",
      "hgs.1.low3.bn1.bias torch.Size([256])\n",
      "hgs.1.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.1.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.1.low3.bn2.weight torch.Size([128])\n",
      "hgs.1.low3.bn2.bias torch.Size([128])\n",
      "hgs.1.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.1.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.1.low3.bn3.weight torch.Size([128])\n",
      "hgs.1.low3.bn3.bias torch.Size([128])\n",
      "hgs.1.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.1.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.1.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.1.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.coordconv.conv.weight torch.Size([256, 261, 1, 1])\n",
      "hgs.2.coordconv.conv.bias torch.Size([256])\n",
      "hgs.2.up1.bn1.weight torch.Size([256])\n",
      "hgs.2.up1.bn1.bias torch.Size([256])\n",
      "hgs.2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.up1.bn2.weight torch.Size([128])\n",
      "hgs.2.up1.bn2.bias torch.Size([128])\n",
      "hgs.2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.up1.bn3.weight torch.Size([128])\n",
      "hgs.2.up1.bn3.bias torch.Size([128])\n",
      "hgs.2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low1.bn1.weight torch.Size([256])\n",
      "hgs.2.low1.bn1.bias torch.Size([256])\n",
      "hgs.2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low1.bn2.weight torch.Size([128])\n",
      "hgs.2.low1.bn2.bias torch.Size([128])\n",
      "hgs.2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low1.bn3.weight torch.Size([128])\n",
      "hgs.2.low1.bn3.bias torch.Size([128])\n",
      "hgs.2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low2.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low2.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low2.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.low2.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low2.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low2.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low2.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.low2.low2.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low2.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low2.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low2.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.low2.low2.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low2.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.low2.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.2.low3.bn1.weight torch.Size([256])\n",
      "hgs.2.low3.bn1.bias torch.Size([256])\n",
      "hgs.2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.2.low3.bn2.weight torch.Size([128])\n",
      "hgs.2.low3.bn2.bias torch.Size([128])\n",
      "hgs.2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.2.low3.bn3.weight torch.Size([128])\n",
      "hgs.2.low3.bn3.bias torch.Size([128])\n",
      "hgs.2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.coordconv.conv.weight torch.Size([256, 261, 1, 1])\n",
      "hgs.3.coordconv.conv.bias torch.Size([256])\n",
      "hgs.3.up1.bn1.weight torch.Size([256])\n",
      "hgs.3.up1.bn1.bias torch.Size([256])\n",
      "hgs.3.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.up1.bn2.weight torch.Size([128])\n",
      "hgs.3.up1.bn2.bias torch.Size([128])\n",
      "hgs.3.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.up1.bn3.weight torch.Size([128])\n",
      "hgs.3.up1.bn3.bias torch.Size([128])\n",
      "hgs.3.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low1.bn1.weight torch.Size([256])\n",
      "hgs.3.low1.bn1.bias torch.Size([256])\n",
      "hgs.3.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low1.bn2.weight torch.Size([128])\n",
      "hgs.3.low1.bn2.bias torch.Size([128])\n",
      "hgs.3.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low1.bn3.weight torch.Size([128])\n",
      "hgs.3.low1.bn3.bias torch.Size([128])\n",
      "hgs.3.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.up1.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.low2.up1.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.up1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.up1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.up1.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.up1.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.up1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.low2.up1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.up1.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.up1.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.up1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.low2.up1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.up1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.up1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low1.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low1.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low1.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.low1.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low1.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low1.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low1.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.low2.low1.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low1.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low1.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low1.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.low2.low1.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low1.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.low1.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low2.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low2.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low2.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.low2.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low2.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low2.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low2.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.low2.low2.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low2.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low2.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low2.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.low2.low2.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low2.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.low2.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low3.bn1.weight torch.Size([256])\n",
      "hgs.3.low2.low3.bn1.bias torch.Size([256])\n",
      "hgs.3.low2.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low2.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low3.bn2.weight torch.Size([128])\n",
      "hgs.3.low2.low3.bn2.bias torch.Size([128])\n",
      "hgs.3.low2.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low2.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low2.low3.bn3.weight torch.Size([128])\n",
      "hgs.3.low2.low3.bn3.bias torch.Size([128])\n",
      "hgs.3.low2.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low2.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low2.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low2.low3.skip_layer.conv.bias torch.Size([256])\n",
      "hgs.3.low3.bn1.weight torch.Size([256])\n",
      "hgs.3.low3.bn1.bias torch.Size([256])\n",
      "hgs.3.low3.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "hgs.3.low3.conv1.conv.bias torch.Size([128])\n",
      "hgs.3.low3.bn2.weight torch.Size([128])\n",
      "hgs.3.low3.bn2.bias torch.Size([128])\n",
      "hgs.3.low3.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "hgs.3.low3.conv2.conv.bias torch.Size([128])\n",
      "hgs.3.low3.bn3.weight torch.Size([128])\n",
      "hgs.3.low3.bn3.bias torch.Size([128])\n",
      "hgs.3.low3.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "hgs.3.low3.conv3.conv.bias torch.Size([256])\n",
      "hgs.3.low3.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "hgs.3.low3.skip_layer.conv.bias torch.Size([256])\n",
      "features.0.0.bn1.weight torch.Size([256])\n",
      "features.0.0.bn1.bias torch.Size([256])\n",
      "features.0.0.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "features.0.0.conv1.conv.bias torch.Size([128])\n",
      "features.0.0.bn2.weight torch.Size([128])\n",
      "features.0.0.bn2.bias torch.Size([128])\n",
      "features.0.0.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "features.0.0.conv2.conv.bias torch.Size([128])\n",
      "features.0.0.bn3.weight torch.Size([128])\n",
      "features.0.0.bn3.bias torch.Size([128])\n",
      "features.0.0.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "features.0.0.conv3.conv.bias torch.Size([256])\n",
      "features.0.0.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.0.0.skip_layer.conv.bias torch.Size([256])\n",
      "features.0.1.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.0.1.conv.bias torch.Size([256])\n",
      "features.0.1.bn.weight torch.Size([256])\n",
      "features.0.1.bn.bias torch.Size([256])\n",
      "features.1.0.bn1.weight torch.Size([256])\n",
      "features.1.0.bn1.bias torch.Size([256])\n",
      "features.1.0.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "features.1.0.conv1.conv.bias torch.Size([128])\n",
      "features.1.0.bn2.weight torch.Size([128])\n",
      "features.1.0.bn2.bias torch.Size([128])\n",
      "features.1.0.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "features.1.0.conv2.conv.bias torch.Size([128])\n",
      "features.1.0.bn3.weight torch.Size([128])\n",
      "features.1.0.bn3.bias torch.Size([128])\n",
      "features.1.0.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "features.1.0.conv3.conv.bias torch.Size([256])\n",
      "features.1.0.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.1.0.skip_layer.conv.bias torch.Size([256])\n",
      "features.1.1.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.1.1.conv.bias torch.Size([256])\n",
      "features.1.1.bn.weight torch.Size([256])\n",
      "features.1.1.bn.bias torch.Size([256])\n",
      "features.2.0.bn1.weight torch.Size([256])\n",
      "features.2.0.bn1.bias torch.Size([256])\n",
      "features.2.0.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "features.2.0.conv1.conv.bias torch.Size([128])\n",
      "features.2.0.bn2.weight torch.Size([128])\n",
      "features.2.0.bn2.bias torch.Size([128])\n",
      "features.2.0.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "features.2.0.conv2.conv.bias torch.Size([128])\n",
      "features.2.0.bn3.weight torch.Size([128])\n",
      "features.2.0.bn3.bias torch.Size([128])\n",
      "features.2.0.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "features.2.0.conv3.conv.bias torch.Size([256])\n",
      "features.2.0.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.2.0.skip_layer.conv.bias torch.Size([256])\n",
      "features.2.1.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.2.1.conv.bias torch.Size([256])\n",
      "features.2.1.bn.weight torch.Size([256])\n",
      "features.2.1.bn.bias torch.Size([256])\n",
      "features.3.0.bn1.weight torch.Size([256])\n",
      "features.3.0.bn1.bias torch.Size([256])\n",
      "features.3.0.conv1.conv.weight torch.Size([128, 256, 1, 1])\n",
      "features.3.0.conv1.conv.bias torch.Size([128])\n",
      "features.3.0.bn2.weight torch.Size([128])\n",
      "features.3.0.bn2.bias torch.Size([128])\n",
      "features.3.0.conv2.conv.weight torch.Size([128, 128, 3, 3])\n",
      "features.3.0.conv2.conv.bias torch.Size([128])\n",
      "features.3.0.bn3.weight torch.Size([128])\n",
      "features.3.0.bn3.bias torch.Size([128])\n",
      "features.3.0.conv3.conv.weight torch.Size([256, 128, 1, 1])\n",
      "features.3.0.conv3.conv.bias torch.Size([256])\n",
      "features.3.0.skip_layer.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.3.0.skip_layer.conv.bias torch.Size([256])\n",
      "features.3.1.conv.weight torch.Size([256, 256, 1, 1])\n",
      "features.3.1.conv.bias torch.Size([256])\n",
      "features.3.1.bn.weight torch.Size([256])\n",
      "features.3.1.bn.bias torch.Size([256])\n",
      "out_heatmaps.0.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_heatmaps.0.conv.bias torch.Size([68])\n",
      "out_heatmaps.1.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_heatmaps.1.conv.bias torch.Size([68])\n",
      "out_heatmaps.2.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_heatmaps.2.conv.bias torch.Size([68])\n",
      "out_heatmaps.3.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_heatmaps.3.conv.bias torch.Size([68])\n",
      "out_edgemaps.0.conv.weight torch.Size([9, 256, 1, 1])\n",
      "out_edgemaps.0.conv.bias torch.Size([9])\n",
      "out_edgemaps.1.conv.weight torch.Size([9, 256, 1, 1])\n",
      "out_edgemaps.1.conv.bias torch.Size([9])\n",
      "out_edgemaps.2.conv.weight torch.Size([9, 256, 1, 1])\n",
      "out_edgemaps.2.conv.bias torch.Size([9])\n",
      "out_edgemaps.3.conv.weight torch.Size([9, 256, 1, 1])\n",
      "out_edgemaps.3.conv.bias torch.Size([9])\n",
      "out_pointmaps.0.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_pointmaps.0.conv.bias torch.Size([68])\n",
      "out_pointmaps.1.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_pointmaps.1.conv.bias torch.Size([68])\n",
      "out_pointmaps.2.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_pointmaps.2.conv.bias torch.Size([68])\n",
      "out_pointmaps.3.conv.weight torch.Size([68, 256, 1, 1])\n",
      "out_pointmaps.3.conv.bias torch.Size([68])\n",
      "merge_edgemaps.0.conv.weight torch.Size([256, 9, 1, 1])\n",
      "merge_edgemaps.0.conv.bias torch.Size([256])\n",
      "merge_edgemaps.1.conv.weight torch.Size([256, 9, 1, 1])\n",
      "merge_edgemaps.1.conv.bias torch.Size([256])\n",
      "merge_edgemaps.2.conv.weight torch.Size([256, 9, 1, 1])\n",
      "merge_edgemaps.2.conv.bias torch.Size([256])\n",
      "merge_pointmaps.0.conv.weight torch.Size([256, 68, 1, 1])\n",
      "merge_pointmaps.0.conv.bias torch.Size([256])\n",
      "merge_pointmaps.1.conv.weight torch.Size([256, 68, 1, 1])\n",
      "merge_pointmaps.1.conv.bias torch.Size([256])\n",
      "merge_pointmaps.2.conv.weight torch.Size([256, 68, 1, 1])\n",
      "merge_pointmaps.2.conv.bias torch.Size([256])\n",
      "merge_features.0.conv.weight torch.Size([256, 256, 1, 1])\n",
      "merge_features.0.conv.bias torch.Size([256])\n",
      "merge_features.1.conv.weight torch.Size([256, 256, 1, 1])\n",
      "merge_features.1.conv.bias torch.Size([256])\n",
      "merge_features.2.conv.weight torch.Size([256, 256, 1, 1])\n",
      "merge_features.2.conv.bias torch.Size([256])\n",
      "merge_heatmaps.0.conv.weight torch.Size([256, 68, 1, 1])\n",
      "merge_heatmaps.0.conv.bias torch.Size([256])\n",
      "merge_heatmaps.1.conv.weight torch.Size([256, 68, 1, 1])\n",
      "merge_heatmaps.1.conv.bias torch.Size([256])\n",
      "merge_heatmaps.2.conv.weight torch.Size([256, 68, 1, 1])\n",
      "merge_heatmaps.2.conv.bias torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net_300W.named_parameters():\n",
    "    print(name, param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_params(source_model,target_model):\n",
    "    source_state_dict = source_model.state_dict()\n",
    "    target_state_dict = target_model.state_dict()\n",
    "\n",
    "    # Load matching layers\n",
    "    pretrained_dict = {k: v for k, v in source_state_dict.items() if k in target_state_dict and v.shape == target_state_dict[k].shape}\n",
    "\n",
    "\n",
    "    target_state_dict.update(pretrained_dict)\n",
    "    target_model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_params(net_300W,net_WFLW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Config:\n",
    "    def __init__(self):\n",
    "            self.data_definition = \"WFLW\"\n",
    "            self.train_tsv_file = 'pub_annot/WFLW/train.tsv'\n",
    "            self.val_tsv_file = 'pub_annot/WFLW/test.tsv'\n",
    "            self.train_pic_dir = 'pub_dataset/WFLW/WFLW_images'\n",
    "            self.val_pic_dir = 'pub_dataset/WFLW/WFLW_images'\n",
    "            self.loader_type = 'alignment'\n",
    "            self.batch_size = 16\n",
    "            self.val_batch_size = 32\n",
    "            self.train_num_workers = 1\n",
    "            self.val_num_workers = 1\n",
    "            self.width = 256\n",
    "            self.height = 256\n",
    "            self.channels = 3\n",
    "            self.means = (127.5, 127.5, 127.5)\n",
    "            self.scale = 0.00784313725490196\n",
    "            self.classes_num = [98, 9, 98]\n",
    "            self.crop_op = True\n",
    "            self.aug_prob = 1.0\n",
    "            self.label_num = 12\n",
    "            self.edge_info = (\n",
    "                (False, (\n",
    "                    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
    "                    27,\n",
    "                    28, 29, 30, 31, 32)),  # FaceContour\n",
    "                (True, (33, 34, 35, 36, 37, 38, 39, 40, 41)),  # RightEyebrow\n",
    "                (True, (42, 43, 44, 45, 46, 47, 48, 49, 50)),  # LeftEyebrow\n",
    "                (False, (51, 52, 53, 54)),  # NoseLine\n",
    "                (False, (55, 56, 57, 58, 59)),  # Nose\n",
    "                (True, (60, 61, 62, 63, 64, 65, 66, 67)),  # RightEye\n",
    "                (True, (68, 69, 70, 71, 72, 73, 74, 75)),  # LeftEye\n",
    "                (True, (76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87)),  # OuterLip\n",
    "                (True, (88, 89, 90, 91, 92, 93, 94, 95)),  # InnerLip\n",
    "            )\n",
    "            self.flip_mapping = (\n",
    "                [0, 32], [1, 31], [2, 30], [3, 29], [4, 28], [5, 27], [6, 26], [7, 25], [8, 24], [9, 23], [10, 22],\n",
    "                [11, 21], [12, 20], [13, 19], [14, 18], [15, 17],  # cheek\n",
    "                [33, 46], [34, 45], [35, 44], [36, 43], [37, 42], [38, 50], [39, 49], [40, 48], [41, 47],  # elbrow\n",
    "                [60, 72], [61, 71], [62, 70], [63, 69], [64, 68], [65, 75], [66, 74], [67, 73],\n",
    "                [55, 59], [56, 58],\n",
    "                [76, 82], [77, 81], [78, 80], [87, 83], [86, 84],\n",
    "                [88, 92], [89, 91], [95, 93], [96, 97]\n",
    "            )\n",
    "            self.encoder_type = 'default'\n",
    "\n",
    "            # Val\n",
    "            self.norm_type = 'default'\n",
    "            self.nme_left_index = 60\n",
    "            self.nme_right_index = 72\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = Data_Config()\n",
    "train_loader = get_dataloader(data_config, data_type='train', world_rank=0, world_size=1)\n",
    "val_loader = get_dataloader(data_config, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from lib.loss import *\n",
    "from lib.metric import NME, FR_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Config:\n",
    "    def __init__(self):\n",
    "        # self.classes_num = [68, 9, 68]\n",
    "        self.nstack = 4\n",
    "        # self.add_coord = True\n",
    "        # self.decoder_type = \"default\"\n",
    "        # self.width = 256\n",
    "        # self.height = 256\n",
    "        self.use_AAM = True\n",
    "        self.label_num = self.nstack * 3 if self.use_AAM else self.nstack\n",
    "\n",
    "        self.loss_func = \"STARLoss_v2\"\n",
    "\n",
    "        # STAR Loss paras\n",
    "        self.star_w = 1\n",
    "        self.star_dist = 'smoothl1'\n",
    "\n",
    "        self.loss_weights, self.criterion_labels, self.metrics = self.set_criterions()\n",
    "        self.criterions = self.get_criterions()\n",
    "\n",
    "        self.batch_weight = 1.0\n",
    "\n",
    "        self.optimizer = \"adam\"\n",
    "        self.learn_rate = 0.001\n",
    "        self.weight_decay = 0.00001\n",
    "        self.betas = [0.9, 0.999]\n",
    "        self.gamma = 0.9\n",
    "        self.milestones = [10*i for i in range(2,10)]\n",
    "\n",
    "    def set_criterions(self):\n",
    "        loss_weights, criterions, metrics = [], [], []\n",
    "        for i in range(self.nstack):\n",
    "            factor = (2 ** i) / (2 ** (self.nstack - 1))\n",
    "            if self.use_AAM:\n",
    "                loss_weights += [factor * weight for weight in [1.0, 10.0, 10.0]]\n",
    "                criterions += [self.loss_func, \"AWingLoss\", \"AWingLoss\"]\n",
    "                metrics += [\"NME\", None, None]\n",
    "            else:\n",
    "                loss_weights += [factor * weight for weight in [1.0]]\n",
    "                criterions += [self.loss_func, ]\n",
    "                metrics += [\"NME\", ]\n",
    "        return loss_weights, criterions, metrics\n",
    "    \n",
    "    def get_criterions(self):\n",
    "        criterions = []\n",
    "        for k in range(self.label_num):\n",
    "            label = self.criterion_labels[k]\n",
    "            if label == \"AWingLoss\":\n",
    "                criterion = AWingLoss()\n",
    "            elif label == \"smoothl1\":\n",
    "                criterion = SmoothL1Loss()\n",
    "            elif label == \"l1\":\n",
    "                criterion = F.l1_loss\n",
    "            elif label == 'l2':\n",
    "                criterion = F.mse_loss\n",
    "            elif label == \"STARLoss\":\n",
    "                criterion = STARLoss(dist=self.star_dist, w=self.star_w)\n",
    "            elif label == \"STARLoss_v2\":\n",
    "                criterion = STARLoss_v2(dist=self.star_dist, w=self.star_w)\n",
    "            else:\n",
    "                assert False\n",
    "            criterions.append(criterion)\n",
    "        return criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = Train_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lib.metric import NME, FR_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the LightningModule\n",
    "class LitSTAR(L.LightningModule):\n",
    "    def __init__(self, net, data_config, model_config, train_config):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.data_config = data_config\n",
    "        self.model_config = model_config\n",
    "        self.train_config = train_config\n",
    "        self.ave_losses = [0] * self.train_config.label_num\n",
    "        self.list_nmes = [[] for i in range(self.data_config.label_num)]\n",
    "        \n",
    "    def training_step(self, sample, batch_idx):\n",
    "\n",
    "        imgs = sample[\"data\"].float()\n",
    "\n",
    "        labels = []\n",
    "        if isinstance(sample[\"label\"], list):\n",
    "            for label in sample[\"label\"]:\n",
    "                label = label.float()\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            label = sample[\"label\"].float()\n",
    "            for k in range(label.shape[1]):\n",
    "                labels.append(label[:, k])\n",
    "        labels = self.model_config.nstack * labels\n",
    "\n",
    "        # forward\n",
    "        output, heatmaps, landmarks = self.net(imgs)\n",
    "\n",
    "\n",
    "        losses, sum_loss = self.compute_loss(output, labels, heatmaps, landmarks)\n",
    "        self.ave_losses = list(map(sum, zip(self.ave_losses, losses)))\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"sum_loss\", sum_loss, prog_bar=True)\n",
    "        self.log(\"AVG_loss\",avg_loss,prog_bar=True)\n",
    "        return sum_loss\n",
    "    \n",
    "    def validation_step(self,sample,batch_idx):\n",
    "        \n",
    "        metric_nme = NME(nme_left_index=self.data_config.nme_left_index, nme_right_index=self.data_config.nme_right_index)\n",
    "        metric_fr_auc = FR_AUC(data_definition=self.data_config.data_definition)\n",
    "\n",
    "        output_pd = None\n",
    "\n",
    "        imgs = sample[\"data\"].float()\n",
    "\n",
    "        labels = []\n",
    "        if isinstance(sample[\"label\"], list):\n",
    "            for label in sample[\"label\"]:\n",
    "                label = label.float()\n",
    "                labels.append(label)\n",
    "        else:\n",
    "            label = sample[\"label\"].float()\n",
    "            for k in range(label.shape[1]):\n",
    "                labels.append(label[:, k])\n",
    "        labels = self.model_config.nstack * labels\n",
    "\n",
    "        # forward\n",
    "        output, heatmaps, landmarks = self.net(imgs)\n",
    "\n",
    "        for k in range(self.data_config.label_num):\n",
    "            if self.train_config.metrics[k] is not None:\n",
    "                self.list_nmes[k] += metric_nme.test(output[k], labels[k])\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metric_nme = NME(nme_left_index=self.data_config.nme_left_index, nme_right_index=self.data_config.nme_right_index)\n",
    "        metric_fr_auc = FR_AUC(data_definition=self.data_config.data_definition)\n",
    "        metrics = [[torch.mean(torch.tensor(nmes)), ] + metric_fr_auc.test(torch.tensor(nmes)) for nmes in self.list_nmes]\n",
    "\n",
    "        # self.log(\"Val_metrics\",metrics)\n",
    "        for k, metric in enumerate(metrics):\n",
    "            nme, fr, auc = metric\n",
    "            # print(metric)\n",
    "            if not torch.isnan(nme):\n",
    "                stack_no = k//3\n",
    "                self.log(f\"Stack{stack_no}_NME\",nme,on_epoch=True)\n",
    "                self.log(f\"Stack{stack_no}_FR\",fr,on_epoch=True)\n",
    "                self.log(f\"Stack{stack_no}_AUC\",auc,on_epoch=True)\n",
    "                # print(\"Val/Metric{:3d} in this epoch: [NME {:.6f}, FR {:.6f}, AUC {:.6f}]\".format(\n",
    "                #     k, metric[0], metric[1], metric[2]))\n",
    "\n",
    "        self.list_nmes = [[] for i in range(self.data_config.label_num)]\n",
    "\n",
    "\n",
    "    def compute_loss(self, output, labels, heatmap=None, landmarks=None):\n",
    "        batch_weight = self.train_config.batch_weight\n",
    "        sum_loss = 0\n",
    "        losses = list()\n",
    "        # print(self.train_config.criterion_labels)\n",
    "        for k in range(self.train_config.label_num):\n",
    "            \n",
    "            if self.train_config.criterion_labels[k] in ['smoothl1', 'l1', 'l2', 'WingLoss', 'AWingLoss']:\n",
    "                loss = self.train_config.criterions[k](output[k], labels[k])\n",
    "            elif self.train_config.criterion_labels[k] in [\"STARLoss\", \"STARLoss_v2\"]:\n",
    "                _k = int(k / 3) if self.train_config.use_AAM else k\n",
    "                loss = self.train_config.criterions[k](heatmap[_k], labels[k])\n",
    "            else:\n",
    "                assert NotImplementedError\n",
    "            loss = batch_weight * loss\n",
    "            sum_loss += self.train_config.loss_weights[k] * loss\n",
    "            losses.append(loss)\n",
    "        return losses, sum_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = self.net.parameters()\n",
    "\n",
    "        optimizer = None\n",
    "        if self.train_config.optimizer == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                params,\n",
    "                lr=self.train_config.learn_rate,\n",
    "                momentum=self.train_config.momentum,\n",
    "                weight_decay=self.train_config.weight_decay,\n",
    "                nesterov=self.train_config.nesterov)\n",
    "        elif self.train_config.optimizer == \"adam\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                params,\n",
    "                lr=self.train_config.learn_rate)\n",
    "        elif self.train_config.optimizer == \"rmsprop\":\n",
    "            optimizer = torch.optim.RMSprop(\n",
    "                params,\n",
    "                lr=self.train_config.learn_rate,\n",
    "                momentum=self.train_config.momentum,\n",
    "                alpha=self.train_config.alpha,\n",
    "                eps=self.train_config.epsilon,\n",
    "                weight_decay=self.train_config.weight_decay\n",
    "            )\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        config_dict = {\n",
    "            \"optimizer\" : optimizer,\n",
    "            \"lr_scheduler\" : {\n",
    "                \"scheduler\" : torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.train_config.milestones, gamma=self.train_config.gamma)\n",
    "            }\n",
    "        }\n",
    "        return config_dict\n",
    "\n",
    "\n",
    "# init the module\n",
    "STAR = LitSTAR(net_WFLW, data_config, config_WFLW, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = None\n",
    "if ckpt_path is not None:\n",
    "    STAR = LitSTAR.load_from_checkpoint(ckpt_path,\n",
    "    net = net, \n",
    "    data_config = data_config, \n",
    "    model_config = config_WFLW,\n",
    "    train_config = train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/groups/sammer/haogeh/Python/asymm/STAR/.venv/l ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type           | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | net  | StackedHGNetV1 | 17.2 M | train\n",
      "------------------------------------------------\n",
      "17.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.2 M    Total params\n",
      "68.709    Total estimated model params size (MB)\n",
      "916       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49703d8058b54a8da42b4898f3e1eeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6812c666aca74416aea06e232272d435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ecf31889da4cc9a75aa6807b9c6199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5636e1361d71474883148e3168b0b31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    576\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    983\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1026\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    206\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:212\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    211\u001b[0m dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m batch, _, __ \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_fetcher)\n\u001b[1;32m    213\u001b[0m \u001b[39m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m()\n\u001b[1;32m    134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[39m# the iterator is empty\u001b[39;00m\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator)\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator, _Sequential):\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     out[i] \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterators[i])\n\u001b[1;32m     79\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m     success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1294\u001b[0m     \u001b[39mif\u001b[39;00m success:\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1132\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/share/software/user/open/python/3.9.0/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/share/software/user/open/python/3.9.0/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/share/software/user/open/python/3.9.0/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/share/software/user/open/python/3.9.0/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/share/software/user/open/python/3.9.0/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m L\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m      2\u001b[0m     max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m     limit_train_batches \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     callbacks\u001b[39m=\u001b[39m[lr_monitor],\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 7\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      8\u001b[0m     model\u001b[39m=\u001b[39;49mSTAR, \n\u001b[1;32m      9\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m     10\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     11\u001b[0m     \u001b[39m# ckpt_path=ckpt_path\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n",
      "File \u001b[0;32m/home/groups/sammer/haogeh/Python/asymm/STAR/.venv/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[39m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     exit(\u001b[39m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    limit_train_batches = None,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[lr_monitor],\n",
    "    )\n",
    "trainer.fit(\n",
    "    model=STAR, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    # ckpt_path=ckpt_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
